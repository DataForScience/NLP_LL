{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "    <div style=\"width: 150px; float: left;\"> <img src=\"data/D4Sci_logo_ball.png\" alt=\"Data For Science, Inc\" align=\"left\" border=\"0\"> </div>\n",
    "    <div style=\"float: left; margin-left: 10px;\"> <h1>Natural Language Processing</h1>\n",
    "<h1>Sequence Modeling</h1>\n",
    "        <p>Bruno Gon√ßalves<br/>\n",
    "        <a href=\"http://www.data4sci.com/\">www.data4sci.com</a><br/>\n",
    "            @bgoncalves, @data4sci</p></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "moNmVfuvnImW"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gzip\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "RANDOM_SEED = 123\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torchview\n",
    "from torchview import draw_graph\n",
    "\n",
    "import watermark\n",
    "\n",
    "%load_ext watermark\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by print out the versions of the libraries we're using for future reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.7\n",
      "IPython version      : 8.12.3\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 24.3.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n",
      "Git hash: 9c8c00758f3a2fa8e55e08f5aad405a157ca5dd2\n",
      "\n",
      "pandas    : 2.2.3\n",
      "matplotlib: 3.8.0\n",
      "torchtext : 0.6.0\n",
      "torch     : 2.3.0\n",
      "numpy     : 1.26.4\n",
      "watermark : 2.4.3\n",
      "torchview : 0.2.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -n -v -m -g -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load default figure style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('./d4sci.mplstyle')\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the text and label fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(tokenize='spacy', tokenizer_language='en_core_web_sm')\n",
    "LABEL = torchtext.data.LabelField(dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset with the proper schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('TEXT_COLUMN_NAME', TEXT), ('LABEL_COLUMN_NAME', LABEL)]\n",
    "\n",
    "dataset = TabularDataset(path='data/IMDB Dataset.csv', format='csv', skip_header=True, fields=fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training, validation, and test partitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "WZ_4jiHVnMxN",
    "outputId": "dfa51c04-4845-44c3-f50b-d36d41f132b8"
   },
   "outputs": [],
   "source": [
    "X_train, X_test = dataset.split(split_ratio=[0.8, 0.2],random_state=random.seed(RANDOM_SEED))\n",
    "X_train, X_validation = X_train.split(split_ratio=[0.85, 0.15],random_state=random.seed(RANDOM_SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: 34000\n",
      "Shape of test data: 10000\n",
      "Shape of validation data: 6000\n"
     ]
    }
   ],
   "source": [
    "print('Shape of training data:', len(X_train))\n",
    "print('Shape of test data:', len(X_test))\n",
    "print('Shape of validation data:', len(X_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-TBwKWPslPa"
   },
   "source": [
    "Build the vocabulary based on the top \"vocabulary_size\" words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 20_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "e8uNrjdtn4A8",
    "outputId": "6cf499d7-7722-4da0-8576-ee0f218cc6e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 20002\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(X_train, max_size=vocabulary_size)\n",
    "LABEL.build_vocab(X_train)\n",
    "\n",
    "print(f'Vocabulary size: {len(TEXT.vocab)}')\n",
    "print(f'Number of classes: {len(LABEL.vocab)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eIQ_zfKLwjKm"
   },
   "source": [
    "## Define Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i7JiHR1stHNF"
   },
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = BucketIterator.splits((X_train, X_validation, X_test),\n",
    "         batch_size=batch_size,\n",
    "         sort_within_batch=False,\n",
    "         sort_key=lambda x: len(x.TEXT_COLUMN_NAME),\n",
    "         device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to define our models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN model\n",
    "\n",
    "As the structure of the model is the same for RNN, GRU, and LSTMs, we implement just one of them for demonstration purposes. We can easily plugin another type of layer as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nQIUm5EjxFNa"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size)        \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, text):        \n",
    "        embedded = self.embedding(text)\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        hidden.squeeze_(0)        \n",
    "        output = self.fc(hidden)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "hidden_size = 256\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ik3NF3faxFmZ"
   },
   "outputs": [],
   "source": [
    "model = RNN(len(TEXT.vocab), # vocabulary_size + 2 for <pad> and <unk>\n",
    "            embedding_size,\n",
    "            hidden_size,\n",
    "            num_classes \n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embedding): Embedding(20002, 128)\n",
      "  (rnn): LSTM(128, 256)\n",
      "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "n_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ik3NF3faxFmZ"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lv9Ny9di6VcI"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T5t1Afn4xO11"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        correct_pred, num_examples = 0, 0\n",
    "\n",
    "        for i, (features, targets) in enumerate(data_loader):\n",
    "\n",
    "            features = features.to(device)\n",
    "            targets = targets.float().to(device)\n",
    "\n",
    "            logits = model(features)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels == targets).sum()\n",
    "            \n",
    "    return correct_pred.float()/num_examples * 100, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this [notebook](https://github.com/rasbt/stat453-deep-learning-ss21/tree/main/L15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1836
    },
    "colab_type": "code",
    "id": "EABZM8Vo0ilB",
    "outputId": "5d45e293-9909-4588-e793-8dfaf72e5c67",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8fa891ef054ef0b798221a4f45e4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 1:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/015 | Batch 000/266 | Loss: 0.7136\n",
      "Epoch: 001/015 | Batch 050/266 | Loss: 0.6994\n",
      "Epoch: 001/015 | Batch 100/266 | Loss: 0.6898\n",
      "Epoch: 001/015 | Batch 150/266 | Loss: 0.6926\n",
      "Epoch: 001/015 | Batch 200/266 | Loss: 0.6961\n",
      "Epoch: 001/015 | Batch 250/266 | Loss: 0.6951\n",
      "training accuracy: 49.94%\n",
      "valid accuracy: 49.82%\n",
      "Time elapsed: 1.06 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9202ad78296d440e9dae3ceb2f7e6376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 2:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002/015 | Batch 000/266 | Loss: 0.6954\n",
      "Epoch: 002/015 | Batch 050/266 | Loss: 0.6933\n",
      "Epoch: 002/015 | Batch 100/266 | Loss: 0.6932\n",
      "Epoch: 002/015 | Batch 150/266 | Loss: 0.6926\n",
      "Epoch: 002/015 | Batch 200/266 | Loss: 0.6930\n",
      "Epoch: 002/015 | Batch 250/266 | Loss: 0.6915\n",
      "training accuracy: 50.14%\n",
      "valid accuracy: 49.38%\n",
      "Time elapsed: 2.04 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3d9d2ebdf24374a79f6b6c23b91a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 3:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003/015 | Batch 000/266 | Loss: 0.6938\n",
      "Epoch: 003/015 | Batch 050/266 | Loss: 0.6949\n",
      "Epoch: 003/015 | Batch 100/266 | Loss: 0.6908\n",
      "Epoch: 003/015 | Batch 150/266 | Loss: 0.6959\n",
      "Epoch: 003/015 | Batch 200/266 | Loss: 0.6924\n",
      "Epoch: 003/015 | Batch 250/266 | Loss: 0.6910\n",
      "training accuracy: 50.25%\n",
      "valid accuracy: 49.63%\n",
      "Time elapsed: 2.99 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd12c3c4288432a81ac6983dbde736a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 4:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004/015 | Batch 000/266 | Loss: 0.6919\n",
      "Epoch: 004/015 | Batch 050/266 | Loss: 0.6913\n",
      "Epoch: 004/015 | Batch 100/266 | Loss: 0.6991\n",
      "Epoch: 004/015 | Batch 150/266 | Loss: 0.6940\n",
      "Epoch: 004/015 | Batch 200/266 | Loss: 0.6953\n",
      "Epoch: 004/015 | Batch 250/266 | Loss: 0.6928\n",
      "training accuracy: 50.09%\n",
      "valid accuracy: 50.45%\n",
      "Time elapsed: 3.85 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c94930f11842cc94df067baae33c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 5:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005/015 | Batch 000/266 | Loss: 0.6930\n",
      "Epoch: 005/015 | Batch 050/266 | Loss: 0.6906\n",
      "Epoch: 005/015 | Batch 100/266 | Loss: 0.6884\n",
      "Epoch: 005/015 | Batch 150/266 | Loss: 0.6900\n",
      "Epoch: 005/015 | Batch 200/266 | Loss: 0.6895\n",
      "Epoch: 005/015 | Batch 250/266 | Loss: 0.6922\n",
      "training accuracy: 50.39%\n",
      "valid accuracy: 50.07%\n",
      "Time elapsed: 4.70 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09c01214ae848bc9900e90da8121d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 6:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006/015 | Batch 000/266 | Loss: 0.6860\n",
      "Epoch: 006/015 | Batch 050/266 | Loss: 0.6872\n",
      "Epoch: 006/015 | Batch 100/266 | Loss: 0.6904\n",
      "Epoch: 006/015 | Batch 150/266 | Loss: 0.6873\n",
      "Epoch: 006/015 | Batch 200/266 | Loss: 0.6886\n",
      "Epoch: 006/015 | Batch 250/266 | Loss: 0.6975\n",
      "training accuracy: 50.15%\n",
      "valid accuracy: 50.95%\n",
      "Time elapsed: 5.57 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc94160ec8c4b4ca59290525ea3cd31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 7:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007/015 | Batch 000/266 | Loss: 0.6876\n",
      "Epoch: 007/015 | Batch 050/266 | Loss: 0.6885\n",
      "Epoch: 007/015 | Batch 100/266 | Loss: 0.6894\n",
      "Epoch: 007/015 | Batch 150/266 | Loss: 0.6884\n",
      "Epoch: 007/015 | Batch 200/266 | Loss: 0.6939\n",
      "Epoch: 007/015 | Batch 250/266 | Loss: 0.6451\n",
      "training accuracy: 68.65%\n",
      "valid accuracy: 66.77%\n",
      "Time elapsed: 6.43 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50e05849647495593c69946a51777ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 8:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008/015 | Batch 000/266 | Loss: 0.5576\n",
      "Epoch: 008/015 | Batch 050/266 | Loss: 0.6149\n",
      "Epoch: 008/015 | Batch 100/266 | Loss: 0.4773\n",
      "Epoch: 008/015 | Batch 150/266 | Loss: 0.3983\n",
      "Epoch: 008/015 | Batch 200/266 | Loss: 0.3978\n",
      "Epoch: 008/015 | Batch 250/266 | Loss: 0.5196\n",
      "training accuracy: 87.54%\n",
      "valid accuracy: 83.55%\n",
      "Time elapsed: 7.31 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2fdbb12908a46e9b2080cbfcbd33294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 9:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009/015 | Batch 000/266 | Loss: 0.2548\n",
      "Epoch: 009/015 | Batch 050/266 | Loss: 0.2753\n",
      "Epoch: 009/015 | Batch 100/266 | Loss: 0.4325\n",
      "Epoch: 009/015 | Batch 150/266 | Loss: 0.3712\n",
      "Epoch: 009/015 | Batch 200/266 | Loss: 0.4064\n",
      "Epoch: 009/015 | Batch 250/266 | Loss: 0.2854\n",
      "training accuracy: 90.88%\n",
      "valid accuracy: 85.28%\n",
      "Time elapsed: 8.21 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4570d7b37d084c4982469734dbc5507a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 10:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010/015 | Batch 000/266 | Loss: 0.1848\n",
      "Epoch: 010/015 | Batch 050/266 | Loss: 0.1800\n",
      "Epoch: 010/015 | Batch 100/266 | Loss: 0.2642\n",
      "Epoch: 010/015 | Batch 150/266 | Loss: 0.2920\n",
      "Epoch: 010/015 | Batch 200/266 | Loss: 0.2054\n",
      "Epoch: 010/015 | Batch 250/266 | Loss: 0.2201\n",
      "training accuracy: 93.53%\n",
      "valid accuracy: 86.18%\n",
      "Time elapsed: 9.12 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8709fcc5eb4364ada699a9934a6e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 11:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011/015 | Batch 000/266 | Loss: 0.1547\n",
      "Epoch: 011/015 | Batch 050/266 | Loss: 0.1785\n",
      "Epoch: 011/015 | Batch 100/266 | Loss: 0.1617\n",
      "Epoch: 011/015 | Batch 150/266 | Loss: 0.0838\n",
      "Epoch: 011/015 | Batch 200/266 | Loss: 0.2815\n",
      "Epoch: 011/015 | Batch 250/266 | Loss: 0.2952\n",
      "training accuracy: 95.04%\n",
      "valid accuracy: 86.00%\n",
      "Time elapsed: 9.93 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285d5c68f33948bc8e3372db01549100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 12:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012/015 | Batch 000/266 | Loss: 0.1977\n",
      "Epoch: 012/015 | Batch 050/266 | Loss: 0.1446\n",
      "Epoch: 012/015 | Batch 100/266 | Loss: 0.1537\n",
      "Epoch: 012/015 | Batch 150/266 | Loss: 0.1356\n",
      "Epoch: 012/015 | Batch 200/266 | Loss: 0.2212\n",
      "Epoch: 012/015 | Batch 250/266 | Loss: 0.0900\n",
      "training accuracy: 96.53%\n",
      "valid accuracy: 86.62%\n",
      "Time elapsed: 10.70 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e5c782c0bb468ead61ea7500ca2bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 13:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013/015 | Batch 000/266 | Loss: 0.1361\n",
      "Epoch: 013/015 | Batch 050/266 | Loss: 0.0600\n",
      "Epoch: 013/015 | Batch 100/266 | Loss: 0.0953\n",
      "Epoch: 013/015 | Batch 150/266 | Loss: 0.1170\n",
      "Epoch: 013/015 | Batch 200/266 | Loss: 0.2049\n",
      "Epoch: 013/015 | Batch 250/266 | Loss: 0.0634\n",
      "training accuracy: 97.55%\n",
      "valid accuracy: 86.08%\n",
      "Time elapsed: 11.47 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7adaf6c168504049b57c1d6f13adea97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 14:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014/015 | Batch 000/266 | Loss: 0.0310\n",
      "Epoch: 014/015 | Batch 050/266 | Loss: 0.1754\n",
      "Epoch: 014/015 | Batch 100/266 | Loss: 0.0735\n",
      "Epoch: 014/015 | Batch 150/266 | Loss: 0.1243\n",
      "Epoch: 014/015 | Batch 200/266 | Loss: 0.1415\n",
      "Epoch: 014/015 | Batch 250/266 | Loss: 0.0495\n",
      "training accuracy: 98.08%\n",
      "valid accuracy: 86.80%\n",
      "Time elapsed: 12.25 min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1c371bda5145faa51de5feb465c164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch: 15:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015/015 | Batch 000/266 | Loss: 0.0661\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'epochs': n_epochs\n",
    "    }\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, batch_data in tqdm(enumerate(train_loader), \n",
    "                                      total=len(train_loader), \n",
    "                                      desc='Epoch: %u' % (epoch+1),\n",
    "                                      leave=True):\n",
    "        \n",
    "        text = batch_data.TEXT_COLUMN_NAME.to(device)\n",
    "        labels = batch_data.LABEL_COLUMN_NAME.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(text)\n",
    "        \n",
    "        # Back propagation\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        if not batch_idx % 50:\n",
    "            print (f'Epoch: {epoch+1:03d}/{n_epochs:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n",
    "                   f'Loss: {loss:.4f}')\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        print(f'training accuracy: '\n",
    "              f'{compute_accuracy(model, train_loader, device)[0]:.2f}%'\n",
    "              f'\\nvalid accuracy: '\n",
    "              f'{compute_accuracy(model, valid_loader, device)[0]:.2f}%')\n",
    "    \n",
    "    history['train_loss'].append(loss.to('cpu').detach().numpy())\n",
    "    history['train_acc'].append(compute_accuracy(model, train_loader, device)[0].to('cpu').detach().numpy())\n",
    "    \n",
    "    val_acc, val_loss = compute_accuracy(model, valid_loader, device)\n",
    "    \n",
    "    history['val_acc'].append(val_acc.to('cpu').detach().numpy())\n",
    "    history['val_loss'].append(val_loss.to('cpu').detach().numpy())\n",
    "\n",
    "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
    "    \n",
    "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
    "print(f'Test accuracy: {compute_accuracy(model, test_loader, device)[0]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):    \n",
    "    fig, ax_lst = plt.subplots(1, 2, sharex=True, sharey=False)\n",
    "    \n",
    "    epochs = range(history['epochs'])\n",
    "    \n",
    "    ax_lst[0].plot(epochs, history['train_loss'], label='Training')\n",
    "    ax_lst[0].plot(epochs, history['val_loss'], label='Testing')\n",
    "    ax_lst[0].set_ylabel('Loss')\n",
    "    ax_lst[0].set_xlabel('Epoch')\n",
    "    ax_lst[0].set_xticks(epochs)\n",
    "    \n",
    "    ax_lst[1].plot(epochs, history['train_acc'], label='Training')\n",
    "    ax_lst[1].plot(epochs, history['val_acc'], label='Testing')\n",
    "    ax_lst[1].set_ylabel('Accuracy')\n",
    "    ax_lst[1].set_xlabel('Epoch')\n",
    "    ax_lst[1].set_xticks(epochs)\n",
    "\n",
    "    ax_lst[1].legend()\n",
    "    \n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; overflow: hidden;\">\n",
    "     <img src=\"data/D4Sci_logo_full.png\" alt=\"Data For Science, Inc\" align=\"center\" border=\"0\" width=300px> \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "rnn_lstm_packed_imdb.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
